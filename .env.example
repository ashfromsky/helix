# ============================================
# Helix Configuration
# ============================================
# Copy this file to .env and configure

# ============================================
# AI Provider Configuration
# ============================================
# Choose your AI provider:
# - "demo"     : Template-based (NO API KEY NEEDED) âœ… Default
# - "deepseek" : DeepSeek via OpenRouter (free tier available)
# - "ollama"   : Local Ollama (requires local installation)
# - "groq"     : Groq API (free tier available)

HELIX_AI_PROVIDER=demo

# ============================================
# DeepSeek (via OpenRouter) - Recommended for production
# ============================================
# 1. Sign up at https://openrouter.ai/ (free tier: ~500 requests/day)
# 2. Get your API key from dashboard
# 3. Uncomment and set the key below
# 4. Change HELIX_AI_PROVIDER to "deepseek"

# HELIX_OPENROUTER_API_KEY=sk-or-v1-your-key-here
# HELIX_OPENROUTER_MODEL=deepseek/deepseek-chat

# ============================================
# Ollama (Local) - Best for offline development
# ============================================
# 1. Install Ollama: https://ollama.com/
# 2. Run: ollama pull llama3
# 3. Start server: ollama serve (usually auto-starts)
# 4. Change HELIX_AI_PROVIDER to "ollama"

# HELIX_OLLAMA_HOST=http://localhost:11434
# HELIX_OLLAMA_MODEL=llama3

# ============================================
# Groq - Fastest inference
# ============================================
# 1. Sign up at https://console.groq.com/ (free tier: 14,400 requests/day)
# 2. Get your API key
# 3. Uncomment and set the key below
# 4. Change HELIX_AI_PROVIDER to "groq"

# HELIX_GROQ_API_KEY=gsk_your-key-here
# HELIX_GROQ_MODEL=llama-3.1-70b-versatile

# ============================================
# AI Generation Settings
# ============================================
HELIX_AI_TEMPERATURE=0.7
HELIX_AI_MAX_TOKENS=2000
HELIX_AI_TIMEOUT=30
HELIX_AI_AUTO_FALLBACK=true

# ============================================
# Redis Configuration
# ============================================
HELIX_REDIS_HOST=localhost
HELIX_REDIS_PORT=6379
HELIX_REDIS_DB=0
# HELIX_REDIS_PASSWORD=  # Uncomment if Redis requires password

# ============================================
# Server Configuration
# ============================================
HELIX_PORT=8080
HELIX_HOST=0.0.0.0
HELIX_DEBUG=true
HELIX_RELOAD=true

# ============================================
# Proxy Mode (Recorder)
# ============================================
# HELIX_PROXY_ENABLED=false
# HELIX_PROXY_TARGET_URL=http://localhost:8000
# HELIX_PROXY_RECORD_ONLY_SUCCESS=true
# HELIX_PROXY_FALLBACK_TO_CACHE=true

# ============================================
# Chaos Engineering
# ============================================
# HELIX_CHAOS_ENABLED=false
# HELIX_CHAOS_ERROR_RATE=0.1
# HELIX_CHAOS_LATENCY_RATE=0.15
# HELIX_CHAOS_MIN_DELAY_MS=2000
# HELIX_CHAOS_MAX_DELAY_MS=5000

# ============================================
# Session Management
# ============================================
HELIX_SESSION_TTL=7200
HELIX_SESSION_CLEANUP_INTERVAL=3600

# ============================================
# Logging
# ============================================
HELIX_LOG_LEVEL=INFO
HELIX_LOG_FORMAT=json
# HELIX_LOG_FILE=helix.log